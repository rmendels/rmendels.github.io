{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of Seafloor Depth Gradients for the *ETOPO* and *SRTM30Plus* Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides the [code](#pcode) used to create the *ETOPO* and *SRTM30Plus* seafloor gradient datasets,  as well as provide some justification for the choice of the value of $\\sigma$,  the smoothing paramter, in performing the calculation.  \n",
    "\n",
    "The gradient calculations are performed using a slightly modified version of the *Canny* function in the Python *Scikit-Image* Package.  The *Canny* function in that package calculates the gradients using the *Sobel* functions as well as the edges,  but only edges are returned.  The only modification that has been made to the source code is to return the calculated *x_gradient*,  *y_gradient* and *gradient_magnitude*.\n",
    "\n",
    "The *Canny* function is used,  rather than a direct call to the *Sobel* function,  because it has code to deal with masked values,  in this instance the vaues over land.  In the call to the *Canny* function,  the only value that matters is the value of $\\sigma$ which determines the window of values used to calculate the gradients,  that is the amount of smoothing.  The other values passed to the *Canny* function are used to calculate the edges,  which are ignored in this instance\n",
    "\n",
    "The value of $\\sigma$ that makes the most sense was determined by looking at graphs of the gradients  (below) for different values of $\\sigma$, and assessing how well the shelf break off the west coast is defined. The definition should not be too sharp nor too wide.  The [code](#pcode) below allows anyone to recalculate the gradients using a different value of $\\sigma$.  Note the *ETOPO* and *SRTM30Plus* datasets are at differing resolutions,  so different amounts of smoothing will be needed in order to obtain similar results. The netcdf files on **ERD's** *ERDDAP* server has values of $\\sigma = 7.5$ for the *ETOPO* dataset and $\\sigma = 12.5$ for the *SRTM30Plus* dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the value of $\\sigma$ for the *ETOPO* dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\sigma = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*gradient_magnitude*:\n",
    "\n",
    "![](etopo_mag_sigma_1.png)\n",
    "\n",
    "*x_gradient*:\n",
    "\n",
    "![](etopo_x_grad_sigma_1.png)\n",
    "\n",
    "and *y_gradient*:\n",
    "\n",
    "![](etopo_y_grad_sigma_1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\sigma = 3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*gradient_magnitude*:\n",
    "\n",
    "![](etopo_mag_sigma_3.png)\n",
    "\n",
    "*x_gradient*:\n",
    "\n",
    "![](etopo_x_grad_sigma_3.png)\n",
    "\n",
    "and *y_gradient*:\n",
    "\n",
    "![](etopo_y_grad_sigma_3.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\sigma = 5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*gradient_magnitude*:\n",
    "\n",
    "![](etopo_mag_sigma_5.png)\n",
    "\n",
    "*x_gradient*:\n",
    "\n",
    "![](etopo_x_grad_sigma_5.png)\n",
    "\n",
    "and *y_gradient*:\n",
    "\n",
    "![](etopo_y_grad_sigma_5.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\sigma = 10$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*gradient_magnitude*:\n",
    "\n",
    "![](etopo_mag_sigma_10.png)\n",
    "\n",
    "*x_gradient*:\n",
    "\n",
    "![](etopo_x_grad_sigma_10.png)\n",
    "\n",
    "and *y_gradient*:\n",
    "\n",
    "![](etopo_y_grad_sigma_10.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the value of $\\sigma$ for the *SRTM30Plus* dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\sigma = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*gradient_magnitude*:\n",
    "\n",
    "![](srtm30_mag_sigma_1.png)\n",
    "\n",
    "*x_gradient*:\n",
    "\n",
    "![](srtm30_x_grad_sigma_1.png)\n",
    "\n",
    "and *y_gradient*:\n",
    "\n",
    "![](srtm30_y_grad_sigma_1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\sigma = 5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*gradient_magnitude*:\n",
    "\n",
    "![](srtm30_mag_sigma_5.png)\n",
    "\n",
    "*x_gradient*:\n",
    "\n",
    "![](srtm30_x_grad_sigma_5.png)\n",
    "\n",
    "and *y_gradient*:\n",
    "\n",
    "![](srtm30_y_grad_sigma_5.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\sigma = 10$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*gradient_magnitude*:\n",
    "\n",
    "![](srtm30_mag_sigma_10.png)\n",
    "\n",
    "*x_gradient*:\n",
    "\n",
    "![](srtm30_x_grad_sigma_10.png)\n",
    "\n",
    "and *y_gradient*:\n",
    "\n",
    "![](srtm30_y_grad_sigma_10.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\sigma = 12.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*gradient_magnitude*:\n",
    "\n",
    "![](srtm30_mag_sigma_12.5.png)\n",
    "\n",
    "*x_gradient*:\n",
    "\n",
    "![](srtm30_x_grad_sigma_12.5.png)\n",
    "\n",
    "and *y_gradient*:\n",
    "\n",
    "![](srtm30_y_grad_sigma_12.5.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\sigma = 15$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*gradient_magnitude*:\n",
    "\n",
    "![](srtm30_mag_sigma_15.png)\n",
    "\n",
    "*x_gradient*:\n",
    "\n",
    "![](srtm30_x_grad_sigma_15.png)\n",
    "\n",
    "and *y_gradient*:\n",
    "\n",
    "![](srtm30_y_grad_sigma_15.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pcode'></a>\n",
    "##  Python code for extracting seafloor depth data,  calculating the gradient,  plotting the results, and writing to a netcdf file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# import needed packages\n",
    "from Canny1 import *\n",
    "from cartopy import crs\n",
    "import cmocean\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "import holoviews as hv\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import xarray as xr\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract *ETOPO* data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "\"\"\"Documentation for extract_etopo.py.\n",
    "\n",
    "Program Call and Arguments:\n",
    "    ncdf_file = extract_etopo(file_name, file_base, lat_min, lat_max, lon_min, lon_max)\n",
    "    file_name - name of file with global etopo data.\n",
    "    file_base - base directory of data file location.\n",
    "    lat_min - minimum latitude of extract on (0, 180).\n",
    "    lat_max - maximum latitude of extract on (0, 180).\n",
    "    lon_min - minimum longitude of extract on (0, 360).\n",
    "    lon_max - maximum longitude of extract on (0, 360).\n",
    "\n",
    "Program Description:\n",
    "    extract_etopo extracts etopo data that falls within the bounding box\n",
    "    defined by (lat_min,lat_max,  lon_min,  lon_max.)\n",
    "Depends:\n",
    "    netCDF4.Dataset, numpy.argwhere, numpy.ma.array\n",
    "\"\"\"\n",
    "\n",
    "def extract_etopo(file_name, file_base = '/Users/rmendels/WorkFiles/seafloor_gradient/etopo/',  lat_min = 20., lat_max = 50., lon_min = 230.,  lon_max = 255.):\n",
    "    import numpy as np\n",
    "    import numpy.ma as ma\n",
    "    from netCDF4 import Dataset\n",
    "    nc_file = file_base + file_name\n",
    "    root = Dataset(nc_file)\n",
    "    lat = root.variables['latitude'][:]\n",
    "    lon = root.variables['longitude'][:]\n",
    "    lat_min_index = np.argwhere(lat == lat_min)\n",
    "    lat_min_index = lat_min_index[0, 0]\n",
    "    lat_max_index = np.argwhere(lat == lat_max)\n",
    "    lat_max_index = lat_max_index[0, 0]\n",
    "    lon_min_index = np.argwhere(lon == lon_min)\n",
    "    lon_min_index = lon_min_index[0, 0]\n",
    "    lon_max_index = np.argwhere(lon == lon_max)\n",
    "    lon_max_index = lon_max_index[0, 0]\n",
    "    lon_etopo = lon[lon_min_index:lon_max_index + 1]\n",
    "    lat_etopo = lat[lat_min_index:lat_max_index + 1]\n",
    "    depth = root.variables['altitude'][lat_min_index:lat_max_index + 1, lon_min_index:lon_max_index + 1 ]\n",
    "    root.close()\n",
    "    depth = ma.array(depth, mask = (depth >= 0))\n",
    "    return depth, lon_etopo, lat_etopo\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Extract *SRTM30Plus* data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\"\"\"Documentation for extract_srtm30plus.py.\n",
    "\n",
    "Program Call and Arguments:\n",
    "    ncdf_file = extract_srtm30plus(file_name, file_base, lat_min, lat_max, lon_min, lon_max)\n",
    "    file_name - name of file with global etopo data.\n",
    "    file_base - base directory of data file location.\n",
    "    lat_min - minimum latitude of extract on (0, 180).\n",
    "    lat_max - maximum latitude of extract on (0, 180).\n",
    "    lon_min - minimum longitude of extract on (0, 360).\n",
    "    lon_max - maximum longitude of extract on (0, 360).\n",
    "\n",
    "Program Description:\n",
    "    extract_etopo extracts etopo data that falls within the bounding box\n",
    "    defined by (lat_min,lat_max,  lon_min,  lon_max.)\n",
    "Depends:\n",
    "    netCDF4.Dataset, numpy.argwhere, numpy.ma.array\n",
    "\"\"\"\n",
    "\n",
    "def extract_srtm30plus(file_name, file_base = '/Users/rmendels/WorkFiles/seafloor_gradient/srtm30plus/',  lat_min = 20.004167, lat_max = 50.004167, lon_min = 230.004167,  lon_max = 255.004167):\n",
    "    import numpy as np\n",
    "    import numpy.ma as ma\n",
    "    from netCDF4 import Dataset\n",
    "    nc_file = file_base + file_name\n",
    "    root = Dataset(nc_file)\n",
    "    lat = root.variables['latitude'][:]\n",
    "    lon = root.variables['longitude'][:]\n",
    "    #lat_min_index = np.argwhere(lat == lat_min)\n",
    "    lat_min_index = np.argwhere( np.abs(lat - lat_min) < .00001)\n",
    "    lat_min_index = lat_min_index[0, 0]\n",
    "    #lat_max_index = np.argwhere(lat == lat_max)\n",
    "    lat_max_index = np.argwhere( np.abs(lat_max - lat) < .00001)\n",
    "    lat_max_index = lat_max_index[0, 0]\n",
    "    #lon_min_index = np.argwhere(lon == lon_min)\n",
    "    lon_min_index = np.argwhere( np.abs(lon - lon_min) < .00001)\n",
    "    lon_min_index = lon_min_index[0, 0]\n",
    "    #lon_max_index = np.argwhere(lon == lon_max)\n",
    "    lon_max_index = np.argwhere( np.abs(lon_max - lon) < .00001)\n",
    "    lon_max_index = lon_max_index[0, 0]\n",
    "    lon_srtm30plus = lon[lon_min_index:lon_max_index + 1]\n",
    "    lat_srtm30plus = lat[lat_min_index:lat_max_index + 1]\n",
    "    depth = root.variables['z'][lat_min_index:lat_max_index + 1, lon_min_index:lon_max_index + 1 ]\n",
    "    depth = ma.array(depth, mask = (depth >= 0))\n",
    "    root.close()\n",
    "    return depth, lon_srtm30plus, lat_srtm30plus\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that calls *Canny* function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "## note that for seafloor depth gradient, lower and upper values don't matter\n",
    "## and the returned edges are disregarded\n",
    "def myCanny(myData, myMask, sigma = 10., lower = .8, upper = .9, use_quantiles = True):\n",
    "# calls my version of Canny algorithm,  return needed eliminates masked\n",
    "# because of the way masks operate,  if you read in sst using netcdf4,  then the mask to use is ~sst.mask\n",
    "    edges, y_gradient, x_gradient, magnitude = canny(myData, sigma = sigma, mask = myMask,     low_threshold = lower, high_threshold = upper,\n",
    "                              use_quantiles = use_quantiles)\n",
    "    x_gradient = ma.array(x_gradient, mask = myData.mask)\n",
    "    y_gradient = ma.array(y_gradient, mask = myData.mask)\n",
    "    magnitude = ma.array(magnitude, mask = myData.mask)\n",
    "    return edges, x_gradient, y_gradient, magnitude\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def plot_bathy(depth, latitudes, longitudes, title = ' ', fig_size = ([10, 8])):\n",
    "    myData_xr = xr.DataArray(depth, coords=[latitudes, longitudes], dims=['latitude', 'longitude'], name = 'depth')\n",
    "    myData_xr.plot(cmap = cmocean.cm.deep.reversed())\n",
    "\n",
    "# plots the gradients, as well as the distribution of the gradients\n",
    "def plot_canny_gradient(my_grad, latitudes, longitudes, title = ' ', fig_size = ([10, 8]) ):\n",
    "    fig, axes = plt.subplots(ncols=2)\n",
    "    myData_xr = xr.DataArray(my_grad, coords=[latitudes, longitudes], dims=['latitude', 'longitude'], name = 'gradient')\n",
    "    if(my_grad.min() < 0.):\n",
    "        myData_xr.plot(cmap = cmocean.cm.balance, ax=axes[0])\n",
    "    else:\n",
    "        myData_xr.plot(cmap = cmocean.cm.amp, ax=axes[0])\n",
    "    myData_xr = xr.DataArray(np.abs(my_grad), coords=[latitudes, longitudes], dims=['latitude', 'longitude'], name = 'gradient')\n",
    "    myData_xr.plot.hist(bins = 100, histtype='step', density = True, stacked = True, cumulative=True, ax=axes[1])\n",
    "    plt.title('')\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle(title, y =  1.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to create and write netcdf files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def create_depth_gradient_nc(f_name, base_dir, depths, lats, lons):\n",
    "    from netCDF4 import Dataset, num2date, date2num\n",
    "    import numpy as np\n",
    "    import numpy.ma as ma\n",
    "    file_name = base_dir + f_name +  '_seafloor_gradient.nc'\n",
    "    ncfile  = Dataset(file_name, 'w', format = 'NETCDF4')\n",
    "    latsdim = lats.size\n",
    "    lonsdim = lons.size\n",
    "    #Create Dimensions\n",
    "    latdim = ncfile.createDimension('lat', latsdim)\n",
    "    londim = ncfile.createDimension('lon', lonsdim)\n",
    "    #Create Variables\n",
    "    LatLon_Projection = ncfile.createVariable('LatLon_Projection', 'i4')\n",
    "    latitude = ncfile.createVariable('lat', 'f4', ('lat'), zlib = True, complevel = 2)\n",
    "    longitude = ncfile.createVariable('lon', 'f4', ('lon'), zlib = True, complevel = 2)\n",
    "    # edges = ncfile.createVariable('edges', 'f4', ('time', 'altitude', 'lat', 'lon'), fill_value = -9999.0, zlib = True, complevel = 2)\n",
    "    sea_floor_depth = ncfile.createVariable('sea_floor_depth', 'f4', ( 'lat', 'lon'), fill_value = -99999.0, zlib = True, complevel = 2)\n",
    "    x_gradient = ncfile.createVariable('x_gradient', 'f4', ( 'lat', 'lon'), fill_value = -9999.0, zlib = True, complevel = 2)\n",
    "    y_gradient = ncfile.createVariable('y_gradient', 'f4', ('lat', 'lon'), fill_value = -9999.0, zlib = True, complevel = 2)\n",
    "    magnitude_gradient = ncfile.createVariable('magnitude_gradient', 'f4', ('lat', 'lon'), fill_value = -9999.0, zlib = True, complevel = 2)\n",
    "    # int LatLon_Projection ;\n",
    "    LatLon_Projection.grid_mapping_name = \"latitude_longitude\"\n",
    "    LatLon_Projection.earth_radius = 6367470.\n",
    "    #float lat(lat) ;\n",
    "    latitude._CoordinateAxisType = \"Lat\"\n",
    "    junk = (lats.min(), lats.max())\n",
    "    latitude.actual_range = junk\n",
    "    latitude.axis = \"Y\"\n",
    "    latitude.grid_mapping = \"Equidistant Cylindrical\"\n",
    "    latitude.ioos_category = \"Location\"\n",
    "    latitude.long_name = \"Latitude\"\n",
    "    latitude.reference_datum = \"geographical coordinates, WGS84 projection\"\n",
    "    latitude.standard_name = \"latitude\"\n",
    "    latitude.units = \"degrees_north\"\n",
    "    latitude.valid_max = lats.max()\n",
    "    latitude.valid_min = lats.min()\n",
    "    #float lon(lon) ;\n",
    "    longitude._CoordinateAxisType = \"Lon\"\n",
    "    junk = (lons.min(), lons.max())\n",
    "    longitude.actual_range = junk\n",
    "    longitude.axis = \"X\"\n",
    "    longitude.grid_mapping = \"Equidistant Cylindrical\"\n",
    "    longitude.ioos_category = \"Location\"\n",
    "    longitude.long_name = \"Longitude\"\n",
    "    longitude.reference_datum = \"geographical coordinates, WGS84 projection\"\n",
    "    longitude.standard_name = \"longitude\"\n",
    "    longitude.units = \"degrees_east\"\n",
    "    longitude.valid_max = lons.max()\n",
    "    longitude.valid_min = lons.min()\n",
    "    #float edges(lat, lon) ;\n",
    "    #edges.long_name = \"Frontal Edge\"\n",
    "    #edges.missing_value = -9999.\n",
    "    #edges.grid_mapping = \"LatLon_Projection\"\n",
    "    #edges.coordinates = \"time altitude lat lon \"\n",
    "    #float sea_floor_depth(lat, lon) ;\n",
    "    sea_floor_depth.long_name = \"Sea Floor Depth\"\n",
    "    sea_floor_depth.standard_name = \"sea_floor_depth\"\n",
    "    sea_floor_depth.missing_value = -9999.\n",
    "    sea_floor_depth.grid_mapping = \"LatLon_Projection\"\n",
    "    sea_floor_depth.coordinates = \"lat lon \"\n",
    "    sea_floor_depth.units = 'm'\n",
    "    #float x_gradient(lat, lon) ;\n",
    "    x_gradient.long_name = \"East-West Gradient of sea_floor depth\"\n",
    "    x_gradient.missing_value = -99999.\n",
    "    x_gradient.grid_mapping = \"LatLon_Projection\"\n",
    "    x_gradient.coordinates = \"lat lon \"\n",
    "    x_gradient.units = 'm'\n",
    "    # float y_gradient(lat, lon) ;\n",
    "    y_gradient.long_name = \"North-South Gradient of sea_floor depth\"\n",
    "    y_gradient.missing_value = -9999.\n",
    "    y_gradient.grid_mapping = \"LatLon_Projection\"\n",
    "    y_gradient.coordinates = \"lat lon \"\n",
    "    y_gradient.units = 'm'\n",
    "    # float magnitude( lat, lon) ;\n",
    "    magnitude_gradient.long_name = \"Magnitude of sea_floor depth Gradient\"\n",
    "    magnitude_gradient.missing_value = -9999.\n",
    "    magnitude_gradient.grid_mapping = \"LatLon_Projection\"\n",
    "    magnitude_gradient.coordinates = \"lat lon \"\n",
    "    magnitude_gradient.units = 'm'\n",
    "    ## global\n",
    "    ncfile.title = \"Estimated\" + f_name + \"sea_floor depth x_gradient, y_gradient and gradient magnitude\"\n",
    "    ncfile.cdm_data_type = \"Grid\"\n",
    "    ncfile.Conventions = \"COARDS, CF-1.6, ACDD-1.3\"\n",
    "    ncfile.standard_name_vocabulary = \"CF Standard Name Table v55\"\n",
    "    ncfile.creator_email = \"erd.data@noaa.gov\"\n",
    "    ncfile.creator_name =  \"NOAA NMFS SWFSC ERD\"\n",
    "    ncfile.creator_type =  \"institution\"\n",
    "    ncfile.creator_url  = \"https://www.pfeg.noaa.gov\"\n",
    "    ncfile.Easternmost_Easting = lons.max()\n",
    "    ncfile.Northernmost_Northing = lats.max()\n",
    "    ncfile.Westernmost_Easting = lons.min()\n",
    "    ncfile.Southernmost_Northing =  lats.max()\n",
    "    ncfile.geospatial_lat_max = lats.max()\n",
    "    ncfile.geospatial_lat_min =  lats.min()\n",
    "    ncfile.geospatial_lat_resolution = 0.01\n",
    "    ncfile.geospatial_lat_units = \"degrees_north\"\n",
    "    ncfile.geospatial_lon_max = lons.max()\n",
    "    ncfile.geospatial_lon_min = lons.min()\n",
    "    ncfile.geospatial_lon_resolution = 0.01\n",
    "    ncfile.geospatial_lon_units = \"degrees_east\"\n",
    "    ncfile.infoUrl = \"\"\n",
    "    ncfile.institution = \"NOAA ERD\"\n",
    "    ncfile.keywords = \"\"\n",
    "    ncfile.keywords_vocabulary = \"GCMD Science Keywords\"\n",
    "    ncfile.summary = '''Estimated sea_floor depth  x-gradient, y-gradient and gradient magnitude\n",
    "    using the Python scikit-image canny algorithm  with sigma = 10.,x-gradient, y-gradient and gradient magnitude.\n",
    "    '''\n",
    "    ncfile.license = '''The data may be used and redistributed for free but is not intended\n",
    "    for legal use, since it may contain inaccuracies. Neither the data\n",
    "    Contributor, ERD, NOAA, nor the United States Government, nor any\n",
    "    of their employees or contractors, makes any warranty, express or\n",
    "    implied, including warranties of merchantability and fitness for a\n",
    "    particular purpose, or assumes any legal liability for the accuracy,\n",
    "    completeness, or usefulness, of this information.\n",
    "    '''\n",
    "    history = 'created from ' + f_name + 'using python scikit-image canny algorithm, sigma = 10'\n",
    "    ncfile.history = history\n",
    "    longitude[:] = lons[:]\n",
    "    latitude[:] = lats[:]\n",
    "    sea_floor_depth[:, :] = depths[:, :]\n",
    "    ncfile.close()\n",
    "\n",
    "    \n",
    " def write_depth_gradient_nc(f_name, base_dir, x_gradient, y_gradient, magnitude):\n",
    "    from netCDF4 import Dataset, num2date, date2num\n",
    "    import numpy as np\n",
    "    import numpy.ma as ma\n",
    "    file_name = base_dir + f_name +  '_seafloor_gradient.nc'\n",
    "    ncfile  = Dataset(file_name, 'a')\n",
    "    x_grad = ncfile.variables['x_gradient']\n",
    "    y_grad = ncfile.variables['y_gradient']\n",
    "    mag_grad = ncfile.variables['magnitude_gradient']\n",
    "    x_grad[ :, :] = x_gradient[:, :]\n",
    "    y_grad[ :, :] = y_gradient[:, :]\n",
    "    mag_grad[ :, :] = magnitude[:, :]\n",
    "    ncfile.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified  *Canny* Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "\"\"\"\n",
    "canny.py - Canny Edge detector\n",
    "\n",
    "Reference: Canny, J., A Computational Approach To Edge Detection, IEEE Trans.\n",
    "    Pattern Analysis and Machine Intelligence, 8:679-714, 1986\n",
    "\n",
    "Originally part of CellProfiler, code licensed under both GPL and BSD licenses.\n",
    "Website: http://www.cellprofiler.org\n",
    "Copyright (c) 2003-2009 Massachusetts Institute of Technology\n",
    "Copyright (c) 2009-2011 Broad Institute\n",
    "All rights reserved.\n",
    "Original author: Lee Kamentsky\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "from scipy.ndimage import generate_binary_structure, binary_erosion, label\n",
    "from skimage.filters import gaussian\n",
    "from skimage import dtype_limits, img_as_float\n",
    "from skimage._shared.utils import assert_nD\n",
    "\n",
    "\n",
    "def smooth_with_function_and_mask(image, function, mask):\n",
    "    \"\"\"Smooth an image with a linear function, ignoring masked pixels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : array\n",
    "        Image you want to smooth.\n",
    "    function : callable\n",
    "        A function that does image smoothing.\n",
    "    mask : array\n",
    "        Mask with 1's for significant pixels, 0's for masked pixels.\n",
    "\n",
    "    Notes\n",
    "    ------\n",
    "    This function calculates the fractional contribution of masked pixels\n",
    "    by applying the function to the mask (which gets you the fraction of\n",
    "    the pixel data that's due to significant points). We then mask the image\n",
    "    and apply the function. The resulting values will be lower by the\n",
    "    bleed-over fraction, so you can recalibrate by dividing by the function\n",
    "    on the mask to recover the effect of smoothing from just the significant\n",
    "    pixels.\n",
    "    \"\"\"\n",
    "    bleed_over = function(mask.astype(float))\n",
    "    masked_image = np.zeros(image.shape, image.dtype)\n",
    "    masked_image[mask] = image[mask]\n",
    "    smoothed_image = function(masked_image)\n",
    "    output_image = smoothed_image / (bleed_over + np.finfo(float).eps)\n",
    "    return output_image\n",
    "\n",
    "\n",
    "def canny(image, sigma=1., low_threshold=None, high_threshold=None, mask=None,\n",
    "          use_quantiles=False):\n",
    "    \"\"\"Edge filter an image using the Canny algorithm.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    image : 2D array\n",
    "        Grayscale input image to detect edges on; can be of any dtype.\n",
    "    sigma : float\n",
    "        Standard deviation of the Gaussian filter.\n",
    "    low_threshold : float\n",
    "        Lower bound for hysteresis thresholding (linking edges).\n",
    "        If None, low_threshold is set to 10% of dtype's max.\n",
    "    high_threshold : float\n",
    "        Upper bound for hysteresis thresholding (linking edges).\n",
    "        If None, high_threshold is set to 20% of dtype's max.\n",
    "    mask : array, dtype=bool, optional\n",
    "        Mask to limit the application of Canny to a certain area.\n",
    "    use_quantiles : bool, optional\n",
    "        If True then treat low_threshold and high_threshold as quantiles of the\n",
    "        edge magnitude image, rather than absolute edge magnitude values. If True\n",
    "        then the thresholds must be in the range [0, 1].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : 2D array (image)\n",
    "        The binary edge map.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    skimage.sobel\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The steps of the algorithm are as follows:\n",
    "\n",
    "    * Smooth the image using a Gaussian with ``sigma`` width.\n",
    "\n",
    "    * Apply the horizontal and vertical Sobel operators to get the gradients\n",
    "      within the image. The edge strength is the norm of the gradient.\n",
    "\n",
    "    * Thin potential edges to 1-pixel wide curves. First, find the normal\n",
    "      to the edge at each point. This is done by looking at the\n",
    "      signs and the relative magnitude of the X-Sobel and Y-Sobel\n",
    "      to sort the points into 4 categories: horizontal, vertical,\n",
    "      diagonal and antidiagonal. Then look in the normal and reverse\n",
    "      directions to see if the values in either of those directions are\n",
    "      greater than the point in question. Use interpolation to get a mix of\n",
    "      points instead of picking the one that's the closest to the normal.\n",
    "\n",
    "    * Perform a hysteresis thresholding: first label all points above the\n",
    "      high threshold as edges. Then recursively label any point above the\n",
    "      low threshold that is 8-connected to a labeled point as an edge.\n",
    "\n",
    "    References\n",
    "    -----------\n",
    "    .. [1] Canny, J., A Computational Approach To Edge Detection, IEEE Trans.\n",
    "           Pattern Analysis and Machine Intelligence, 8:679-714, 1986\n",
    "    .. [2] William Green's Canny tutorial\n",
    "           http://dasl.unlv.edu/daslDrexel/alumni/bGreen/www.pages.drexel.edu/_weg22/can_tut.html\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from skimage import feature\n",
    "    >>> # Generate noisy image of a square\n",
    "    >>> im = np.zeros((256, 256))\n",
    "    >>> im[64:-64, 64:-64] = 1\n",
    "    >>> im += 0.2 * np.random.rand(*im.shape)\n",
    "    >>> # First trial with the Canny filter, with the default smoothing\n",
    "    >>> edges1 = feature.canny(im)\n",
    "    >>> # Increase the smoothing for better results\n",
    "    >>> edges2 = feature.canny(im, sigma=3)\n",
    "    \"\"\"\n",
    "\n",
    "    #\n",
    "    # The steps involved:\n",
    "    #\n",
    "    # * Smooth using the Gaussian with sigma above.\n",
    "    #\n",
    "    # * Apply the horizontal and vertical Sobel operators to get the gradients\n",
    "    #   within the image. The edge strength is the sum of the magnitudes\n",
    "    #   of the gradients in each direction.\n",
    "    #\n",
    "    # * Find the normal to the edge at each point using the arctangent of the\n",
    "    #   ratio of the Y sobel over the X sobel - pragmatically, we can\n",
    "    #   look at the signs of X and Y and the relative magnitude of X vs Y\n",
    "    #   to sort the points into 4 categories: horizontal, vertical,\n",
    "    #   diagonal and antidiagonal.\n",
    "    #\n",
    "    # * Look in the normal and reverse directions to see if the values\n",
    "    #   in either of those directions are greater than the point in question.\n",
    "    #   Use interpolation to get a mix of points instead of picking the one\n",
    "    #   that's the closest to the normal.\n",
    "    #\n",
    "    # * Label all points above the high threshold as edges.\n",
    "    # * Recursively label any point above the low threshold that is 8-connected\n",
    "    #   to a labeled point as an edge.\n",
    "    #\n",
    "    # Regarding masks, any point touching a masked point will have a gradient\n",
    "    # that is \"infected\" by the masked point, so it's enough to erode the\n",
    "    # mask by one and then mask the output. We also mask out the border points\n",
    "    # because who knows what lies beyond the edge of the image?\n",
    "    #\n",
    "    assert_nD(image, 2)\n",
    "    dtype_max = dtype_limits(image, clip_negative=False)[1]\n",
    "\n",
    "    if low_threshold is None:\n",
    "        low_threshold = 0.1 * dtype_max\n",
    "    else:\n",
    "        low_threshold = low_threshold / dtype_max\n",
    "\n",
    "    if high_threshold is None:\n",
    "        high_threshold = 0.2 * dtype_max\n",
    "    else:\n",
    "        high_threshold = high_threshold / dtype_max\n",
    "\n",
    "    if mask is None:\n",
    "        mask = np.ones(image.shape, dtype=bool)\n",
    "\n",
    "    def fsmooth(x):\n",
    "        return img_as_float(gaussian(x, sigma, mode='constant'))\n",
    "\n",
    "    smoothed = smooth_with_function_and_mask(image, fsmooth, mask)\n",
    "    jsobel = ndi.sobel(smoothed, axis=1)\n",
    "    isobel = ndi.sobel(smoothed, axis=0)\n",
    "    abs_isobel = np.abs(isobel)\n",
    "    abs_jsobel = np.abs(jsobel)\n",
    "    magnitude = np.hypot(isobel, jsobel)\n",
    "\n",
    "    #\n",
    "    # Make the eroded mask. Setting the border value to zero will wipe\n",
    "    # out the image edges for us.\n",
    "    #\n",
    "    s = generate_binary_structure(2, 2)\n",
    "    eroded_mask = binary_erosion(mask, s, border_value=0)\n",
    "    eroded_mask = eroded_mask & (magnitude > 0)\n",
    "    #\n",
    "    #--------- Find local maxima --------------\n",
    "    #\n",
    "    # Assign each point to have a normal of 0-45 degrees, 45-90 degrees,\n",
    "    # 90-135 degrees and 135-180 degrees.\n",
    "    #\n",
    "    local_maxima = np.zeros(image.shape, bool)\n",
    "    #----- 0 to 45 degrees ------\n",
    "    pts_plus = (isobel >= 0) & (jsobel >= 0) & (abs_isobel >= abs_jsobel)\n",
    "    pts_minus = (isobel <= 0) & (jsobel <= 0) & (abs_isobel >= abs_jsobel)\n",
    "    pts = pts_plus | pts_minus\n",
    "    pts = eroded_mask & pts\n",
    "    # Get the magnitudes shifted left to make a matrix of the points to the\n",
    "    # right of pts. Similarly, shift left and down to get the points to the\n",
    "    # top right of pts.\n",
    "    c1 = magnitude[1:, :][pts[:-1, :]]\n",
    "    c2 = magnitude[1:, 1:][pts[:-1, :-1]]\n",
    "    m = magnitude[pts]\n",
    "    w = abs_jsobel[pts] / abs_isobel[pts]\n",
    "    c_plus = c2 * w + c1 * (1 - w) <= m\n",
    "    c1 = magnitude[:-1, :][pts[1:, :]]\n",
    "    c2 = magnitude[:-1, :-1][pts[1:, 1:]]\n",
    "    c_minus = c2 * w + c1 * (1 - w) <= m\n",
    "    local_maxima[pts] = c_plus & c_minus\n",
    "    #----- 45 to 90 degrees ------\n",
    "    # Mix diagonal and vertical\n",
    "    #\n",
    "    pts_plus = (isobel >= 0) & (jsobel >= 0) & (abs_isobel <= abs_jsobel)\n",
    "    pts_minus = (isobel <= 0) & (jsobel <= 0) & (abs_isobel <= abs_jsobel)\n",
    "    pts = pts_plus | pts_minus\n",
    "    pts = eroded_mask & pts\n",
    "    c1 = magnitude[:, 1:][pts[:, :-1]]\n",
    "    c2 = magnitude[1:, 1:][pts[:-1, :-1]]\n",
    "    m = magnitude[pts]\n",
    "    w = abs_isobel[pts] / abs_jsobel[pts]\n",
    "    c_plus = c2 * w + c1 * (1 - w) <= m\n",
    "    c1 = magnitude[:, :-1][pts[:, 1:]]\n",
    "    c2 = magnitude[:-1, :-1][pts[1:, 1:]]\n",
    "    c_minus = c2 * w + c1 * (1 - w) <= m\n",
    "    local_maxima[pts] = c_plus & c_minus\n",
    "    #----- 90 to 135 degrees ------\n",
    "    # Mix anti-diagonal and vertical\n",
    "    #\n",
    "    pts_plus = (isobel <= 0) & (jsobel >= 0) & (abs_isobel <= abs_jsobel)\n",
    "    pts_minus = (isobel >= 0) & (jsobel <= 0) & (abs_isobel <= abs_jsobel)\n",
    "    pts = pts_plus | pts_minus\n",
    "    pts = eroded_mask & pts\n",
    "    c1a = magnitude[:, 1:][pts[:, :-1]]\n",
    "    c2a = magnitude[:-1, 1:][pts[1:, :-1]]\n",
    "    m = magnitude[pts]\n",
    "    w = abs_isobel[pts] / abs_jsobel[pts]\n",
    "    c_plus = c2a * w + c1a * (1.0 - w) <= m\n",
    "    c1 = magnitude[:, :-1][pts[:, 1:]]\n",
    "    c2 = magnitude[1:, :-1][pts[:-1, 1:]]\n",
    "    c_minus = c2 * w + c1 * (1.0 - w) <= m\n",
    "    local_maxima[pts] = c_plus & c_minus\n",
    "    #----- 135 to 180 degrees ------\n",
    "    # Mix anti-diagonal and anti-horizontal\n",
    "    #\n",
    "    pts_plus = (isobel <= 0) & (jsobel >= 0) & (abs_isobel >= abs_jsobel)\n",
    "    pts_minus = (isobel >= 0) & (jsobel <= 0) & (abs_isobel >= abs_jsobel)\n",
    "    pts = pts_plus | pts_minus\n",
    "    pts = eroded_mask & pts\n",
    "    c1 = magnitude[:-1, :][pts[1:, :]]\n",
    "    c2 = magnitude[:-1, 1:][pts[1:, :-1]]\n",
    "    m = magnitude[pts]\n",
    "    w = abs_jsobel[pts] / abs_isobel[pts]\n",
    "    c_plus = c2 * w + c1 * (1 - w) <= m\n",
    "    c1 = magnitude[1:, :][pts[:-1, :]]\n",
    "    c2 = magnitude[1:, :-1][pts[:-1, 1:]]\n",
    "    c_minus = c2 * w + c1 * (1 - w) <= m\n",
    "    local_maxima[pts] = c_plus & c_minus\n",
    "\n",
    "    #\n",
    "    #---- If use_quantiles is set then calculate the thresholds to use\n",
    "    #\n",
    "    if use_quantiles:\n",
    "        if high_threshold > 1.0 or low_threshold > 1.0:\n",
    "            raise ValueError(\"Quantile thresholds must not be > 1.0\")\n",
    "        if high_threshold < 0.0 or low_threshold < 0.0:\n",
    "            raise ValueError(\"Quantile thresholds must not be < 0.0\")\n",
    "\n",
    "        high_threshold = np.percentile(magnitude, 100.0 * high_threshold)\n",
    "        low_threshold = np.percentile(magnitude, 100.0 * low_threshold)\n",
    "\n",
    "    #\n",
    "    #---- Create two masks at the two thresholds.\n",
    "    #\n",
    "    high_mask = local_maxima & (magnitude >= high_threshold)\n",
    "    low_mask = local_maxima & (magnitude >= low_threshold)\n",
    "\n",
    "    #\n",
    "    # Segment the low-mask, then only keep low-segments that have\n",
    "    # some high_mask component in them\n",
    "    #\n",
    "    strel = np.ones((3, 3), bool)\n",
    "    labels, count = label(low_mask, strel)\n",
    "    if count == 0:\n",
    "        return low_mask\n",
    "\n",
    "    sums = (np.array(ndi.sum(high_mask, labels,\n",
    "                             np.arange(count, dtype=np.int32) + 1),\n",
    "                     copy=False, ndmin=1))\n",
    "    good_label = np.zeros((count + 1,), bool)\n",
    "    good_label[1:] = sums > 0\n",
    "    output_mask = good_label[labels]\n",
    "    return output_mask, isobel, jsobel, magnitude\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def plot_bathy(depth, latitudes, longitudes, title = ' ', fig_size = ([10, 8])):\n",
    "    myData_xr = xr.DataArray(depth, coords=[latitudes, longitudes], dims=['latitude', 'longitude'], name = 'depth')\n",
    "    myData_xr.plot(cmap = cmocean.cm.deep.reversed())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# plots the gradients, as well as the distribution of the gradients\n",
    "def plot_canny_gradient(my_grad, latitudes, longitudes, title = ' ', fig_size = ([10, 8]) ):\n",
    "    fig, axes = plt.subplots(ncols=2)\n",
    "    myData_xr = xr.DataArray(my_grad, coords=[latitudes, longitudes], dims=['latitude', 'longitude'], name = 'gradient')\n",
    "    if(my_grad.min() < 0.):\n",
    "        myData_xr.plot(cmap = cmocean.cm.balance, ax=axes[0])\n",
    "    else:\n",
    "        myData_xr.plot(cmap = cmocean.cm.amp, ax=axes[0])\n",
    "    myData_xr = xr.DataArray(np.abs(my_grad), coords=[latitudes, longitudes], dims=['latitude', 'longitude'], name = 'gradient')\n",
    "    myData_xr.plot.hist(bins = 100, histtype='step', density = True, stacked = True, cumulative=True, ax=axes[1])\n",
    "    plt.title('')\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle(title, y =  1.0)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
